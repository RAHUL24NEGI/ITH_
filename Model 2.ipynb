{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "from deepface import DeepFace\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "crops_v_dir = os.path.join(current_dir, \"gmdb_crops_v1.1.0/gmdb_crops\")\n",
    "images_v_dir = os.path.join(current_dir, \"gmdb_images_v1.1.0/gmdb_images\")\n",
    "metadata_v_dir = os.path.join(current_dir, \"gmdb_metadata_v1.1.0/gmdb_metadata\")\n",
    "\n",
    "metadata_files = {\n",
    "    \"frequent_gallery_images\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/gmdb_frequent_gallery_images_v1.1.0.csv\",\n",
    "    \"frequent_test_images\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/gmdb_frequent_test_images_v1.1.0.csv\",\n",
    "    \"rare_gallery_images\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/gmdb_rare_gallery_images_v1.1.0.csv\",\n",
    "    \"rare_test_images\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/gmdb_rare_test_images_v1.1.0.csv\",\n",
    "    \"syndromes\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/gmdb_syndromes_v1.1.0.tsv\",\n",
    "    \"test_images\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/gmdb_test_images_v1.1.0.csv\",\n",
    "    \"train_images\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/gmdb_train_images_v1.1.0.csv\",\n",
    "    \"val_images\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/gmdb_val_images_v1.1.0.csv\",\n",
    "    \"metadata\": \"/home/student/gmdb_metadata_v1.1.0/gmdb_metadata/image_metadata_v1.1.0.tsv\",\n",
    "}\n",
    "\n",
    "metadata = {name: pd.read_csv(os.path.join(metadata_v_dir, fname), sep=\"\\t\" if fname.endswith(\".tsv\") else \",\")\n",
    "            for name, fname in metadata_files.items()}\n",
    "\n",
    "syndrome_id = {\n",
    "    \"KBG SYNDROME\": 5, \"ANGELMAN SYNDROME\": 6, \"22q11.2 DELETION SYNDROME\": 61, \n",
    "    \"COFFIN-LOWRY SYNDROME\": 76, \"Cornelia de Lange syndrome\": 0, \"CROUZON SYNDROME\": 33,\n",
    "    \"DOWN SYNDROME\": 101, \"FRAGILE X SYNDROME\": 39, \"Kabuki syndrome\": 3,\n",
    "    \"MOWAT-WILSON SYNDROME\": 23, \"Noonan syndrome\": 2, \"PITT-HOPKINS SYNDROME\": 16, \n",
    "    \"SMITH-LEMLI-OPITZ SYNDROME\": 12, \"WILLIAMS-BEUREN SYNDROME\": 1,\n",
    "    \"WIEDEMANN-STEINER SYNDROME\": 7\n",
    "}\n",
    "\n",
    "syndrome_df = metadata[\"syndromes\"]\n",
    "syndrome_df = syndrome_df[syndrome_df[\"syndrome_name\"].isin(syndrome_id.keys())]\n",
    "syndrome_mapping = {name: sid for name, sid in zip(syndrome_df[\"syndrome_name\"], syndrome_df[\"syndrome_id\"])}\n",
    "\n",
    "for key in ['train_images', 'val_images', 'test_images']:\n",
    "    metadata[key]['image_id'] = metadata[key]['image_id'].apply(lambda x: f\"{x}.jpg\")\n",
    "\n",
    "filtered_syndrome_ids = set(syndrome_id.values())\n",
    "\n",
    "filtered_train_images = metadata['train_images'][metadata['train_images']['label'].isin(filtered_syndrome_ids)]\n",
    "filtered_val_images = metadata['val_images'][metadata['val_images']['label'].isin(filtered_syndrome_ids)]\n",
    "filtered_test_images = metadata['test_images'][metadata['test_images']['label'].isin(filtered_syndrome_ids)]\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "def detect_and_align_face(image_path):\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to read image: {image_path}\")\n",
    "            return None\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        faces = detector.detect_faces(img_rgb)\n",
    "        if len(faces) == 0:\n",
    "            print(f\"No face detected in: {image_path}\")\n",
    "            return None\n",
    "\n",
    "        face = faces[0]\n",
    "        x, y, w, h = face['box']\n",
    "        face_img = img_rgb[y:y + h, x:x + w]\n",
    "        return cv2.resize(face_img, (160, 160))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_embeddings(face_img):\n",
    "    try:\n",
    "        embeddings = DeepFace.represent(face_img, model_name='ArcFace', enforce_detection=False)\n",
    "        return embeddings[0]['embedding']\n",
    "    except Exception as e:\n",
    "        print(f\"Error in embedding extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_images_and_labels(image_dir, metadata_df):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in metadata_df.iterrows():\n",
    "        image_path = os.path.join(image_dir, row['image_id'])\n",
    "        aligned_face = detect_and_align_face(image_path)\n",
    "        if aligned_face is not None:\n",
    "            embedding = extract_embeddings(aligned_face)\n",
    "            if embedding is not None:\n",
    "                embeddings.append(embedding)\n",
    "                labels.append(row['label'])\n",
    "            else:\n",
    "                print(f\"Failed to extract embedding for: {image_path}\")\n",
    "        else:\n",
    "            print(f\"No face detected in: {image_path}\")\n",
    "    return np.array(embeddings), np.array(labels)\n",
    "\n",
    "train_embeddings, train_labels = process_images_and_labels(images_v_dir, filtered_train_images)\n",
    "val_embeddings, val_labels = process_images_and_labels(images_v_dir, filtered_val_images)\n",
    "test_embeddings, test_labels = process_images_and_labels(images_v_dir, filtered_test_images)\n",
    "\n",
    "classifier = SVC(kernel='rbf', probability=True)\n",
    "classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "val_preds = classifier.predict(val_embeddings)\n",
    "test_preds = classifier.predict(test_embeddings)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(val_labels, val_preds))\n",
    "print(\"Test Accuracy:\", accuracy_score(test_labels, test_preds))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(test_labels, test_preds))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(test_labels, test_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import top_k_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "accuracy = accuracy_score(test_labels, test_preds)\n",
    "macro_precision = classification_report(test_labels, test_preds, output_dict=True)['macro avg']['precision']\n",
    "macro_recall = classification_report(test_labels, test_preds, output_dict=True)['macro avg']['recall']\n",
    "macro_f1 = classification_report(test_labels, test_preds, output_dict=True)['macro avg']['f1-score']\n",
    "\n",
    "top5_accuracy = top_k_accuracy_score(test_labels, classifier.predict_proba(test_embeddings), k=5)\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Macro Precision: {macro_precision:.4f}\")\n",
    "print(f\"Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"Macro F1-Score: {macro_f1:.4f}\")\n",
    "print(f\"Top-5 Accuracy: {top5_accuracy:.4f}\")\n",
    "\n",
    "class_report = classification_report(test_labels, test_preds, target_names=[str(i) for i in filtered_syndrome_ids], output_dict=True)\n",
    "\n",
    "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[str(i) for i in filtered_syndrome_ids], yticklabels=[str(i) for i in filtered_syndrome_ids])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "class_labels = [str(i) for i in filtered_syndrome_ids]\n",
    "precision = [class_report[label]['precision'] for label in class_labels]\n",
    "recall = [class_report[label]['recall'] for label in class_labels]\n",
    "f1_score = [class_report[label]['f1-score'] for label in class_labels]\n",
    "support = [class_report[label]['support'] for label in class_labels]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "ax[0].bar(class_labels, precision, color='royalblue')\n",
    "ax[0].set_title('Precision by Class')\n",
    "ax[0].set_xlabel('Class')\n",
    "ax[0].set_ylabel('Precision')\n",
    "\n",
    "ax[1].bar(class_labels, recall, color='orange')\n",
    "ax[1].set_title('Recall by Class')\n",
    "ax[1].set_xlabel('Class')\n",
    "ax[1].set_ylabel('Recall')\n",
    "\n",
    "ax[2].bar(class_labels, f1_score, color='green')\n",
    "ax[2].set_title('F1-Score by Class')\n",
    "ax[2].set_xlabel('Class')\n",
    "ax[2].set_ylabel('F1-Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "macro_avg = {\n",
    "    'precision': macro_precision,\n",
    "    'recall': macro_recall,\n",
    "    'f1-score': macro_f1\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.bar(macro_avg.keys(), macro_avg.values(), color=['royalblue', 'orange', 'green'])\n",
    "ax.set_title('Macro Averages')\n",
    "ax.set_ylabel('Score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
